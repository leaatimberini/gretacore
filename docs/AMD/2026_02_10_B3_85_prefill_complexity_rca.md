# B3.85 â€” Prefill Complexity RCA (MI300X)

**Date**: 2026-02-10  
**Phase**: RCA - Performance Characterization  

## Executive Summary
Analysis of prefill scaling from 4k to 32k tokens confirms an $O(N^2)$ complexity with a high constant factor and significant efficiency degradation at extreme context lengths (32k).

## Measured Results
| Context | Prefill Time (s) | Ratio Time/Prev | Verdict |
|---|---|---|---|
| 4,096 | 21.30 | N/A | OK |
| 8,192 | 111.19 | 5.22x (c=2.0x) | OK |
| 16,384 | 463.37 | 4.17x (c=2.0x) | OK |
| 32,768 | 2542.79 | 5.48x (c=2.0x) | **DEGRADED** |

*(Note: 32k data point sourced from B3.88 milestone run)*

## Technical RCA: why $O(N^2)$?
The current implementation of `flash_attention_prefill_kernel` in `attention_kernels.hip` uses a naive triple-loop over queries, keys, and values.

1. **Global Memory Overload**: The kernel reads the entire Key and Value cache from VRAM for every block of queries. It does not use LDS (Shared Memory) tiling to stage and reuse blocks.
2. **Bandwidth Bound**: At 32k context, the amount of data moved between VRAM and CUs ($O(N^2 \times D)$) exceeds the effective bandwidth cache hits, leading to the observed 5.48x jump (vs 4x ideal).
3. **Register Pressure**: The online softmax computation is performed with high register usage, limiting occupancy on the MI300X.

## Verdict
**PASS_RCA_O_N2**: Complexity is confirmed. The infrastructure is ready for the optimization phase.

## Recommendations
- Transition to a **tiled** attention kernel implementation.
- Stage blocks of Keys and Values in **LDS** to reduce VRAM traffic by a factor of the block size (e.g., 64x).
- Target a < 600s prefill time for 32k context as the next milestone.
